{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa398610",
   "metadata": {},
   "source": [
    "# Mini-Project 1: Machine Learning 101\n",
    "\n",
    "Christian Martel (260867191)\n",
    "\n",
    "Luka Loignon (260871296)\n",
    "\n",
    "Marie Guertin (260870552)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62db0c",
   "metadata": {},
   "source": [
    "# PART I: Adult Dataset\n",
    "\n",
    "Prediction task is to determine whether someone makes over 50K a year.\n",
    "https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456d026",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20809070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# other py files\n",
    "import my_validation\n",
    "import my_preprocessing\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a218cb",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4dcf1",
   "metadata": {},
   "source": [
    "### 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19978dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'salary']\n",
    "train_df = pd.read_csv(\"data/adult.data\", usecols = range(15), names = columns)\n",
    "test_df = pd.read_csv(\"data/adult.test\", usecols = range(15), names = columns)\n",
    "display(train_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdca538",
   "metadata": {},
   "source": [
    "### 2. Strip the Object Data\n",
    "\n",
    "Categorical data is not stripped, labels contain left white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84219d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = my_preprocessing.strip_labels(train_df)\n",
    "test_df = my_preprocessing.strip_labels(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a392215",
   "metadata": {},
   "source": [
    "### 3. Remove Useless Columns and Rows\n",
    "\n",
    "From the imported datasets, we observe that the capital-gain and capital-loss columns contain mostly zeros. These columns are not important features so they will be removed.\n",
    "\n",
    "We can observe that the first row of the test dataset contains junk data, so this row will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with too much missing data\n",
    "train_df.drop(columns = ['capital-gain', 'capital-loss'], inplace = True)\n",
    "test_df.drop(columns = ['capital-gain', 'capital-loss'], inplace = True)\n",
    "\n",
    "# remove first row containing junk data\n",
    "test_df.drop(labels=0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30822f0a",
   "metadata": {},
   "source": [
    "### Check all unique values per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcdcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique values for each column\n",
    "for c in train_df.columns:\n",
    "    print(\"{c}: \".format(c=c), train_df[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d333bf",
   "metadata": {},
   "source": [
    "### 4. Data Imputation\n",
    "\n",
    "For continuous data: replace Nan values or invalid values with mean value of column\n",
    "\n",
    "For categorical data: replace Nan values or invalid values with most occurring features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f183154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the invalid entries for each column\n",
    "invalid_entries_dict = {\n",
    "    'age':[],\n",
    "    'workclass':['?'],\n",
    "    'fnlwgt':[],\n",
    "    'education':[],\n",
    "    'education-num':[],\n",
    "    'marital-status':[],\n",
    "    'occupation':['?'],\n",
    "    'relationship':[],\n",
    "    'race':[],\n",
    "    'sex':[],\n",
    "    'hours-per-week':[],\n",
    "    'native-country':['?']\n",
    "}\n",
    "train_df = my_preprocessing.imputation(train_df, invalid_entries_dict)\n",
    "test_df = my_preprocessing.imputation(test_df, invalid_entries_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b9a0c",
   "metadata": {},
   "source": [
    "### 5. Categorical Features One-Hot-Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04095ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop prediction column\n",
    "y_train, y_test = train_df.pop('salary'), test_df.pop('salary')\n",
    "\n",
    "# one-hot-encode categorical features\n",
    "train_df = my_preprocessing.ohe(train_df)\n",
    "test_df = my_preprocessing.ohe(test_df)\n",
    "        \n",
    "# add back prediction column\n",
    "train_df, test_df = pd.concat([train_df, y_train],axis=1), pd.concat([test_df, y_test],axis=1)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffdfb6",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3b12f",
   "metadata": {},
   "source": [
    "### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0105a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# convert to numpy arrays\n",
    "train, test = train_df.to_numpy(), test_df.to_numpy()\n",
    "\n",
    "# random permutations of indices\n",
    "inds = np.random.permutation(range(train.shape[0]))\n",
    "\n",
    "# split into features set and prediction set\n",
    "x, y = train[inds, :-1], train[inds, -1]\n",
    "x_test, y_test = test[:, :-1], test[:, -1]\n",
    "\n",
    "# number of folds for L-fold cross-validation\n",
    "L = 5\n",
    "\n",
    "# range of number of nearest neighbors (K)\n",
    "K_list = range(1,16) # [1,2,...,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db9934",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f94667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn cross-validation on full dataset\n",
    "err_val_matrix, err_train_matrix = my_validation.knn_cross_validation(x, y, K_list, L, my_validation.error_rate)\n",
    "err_val_means = np.mean(err_val_matrix, axis=1)\n",
    "\n",
    "# Visualize\n",
    "plt.title('Error Rate of KNN for Different K Values with Full Dataset')\n",
    "plt.plot(K_list, np.mean(err_train_matrix, axis=1),  label='train')\n",
    "plt.errorbar(K_list, np.mean(err_matrix, axis=1), np.std(err_matrix, axis=1), label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('K (number of neighbours)')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.ylim(0,0.5)\n",
    "plt.show()\n",
    "\n",
    "# The best K parameter is the one providing the smallest error rate\n",
    "best_k = K_list[err_val_means.index(min(err_val_means))]\n",
    "print(\"Best K parameter: {%k}\".format(k=best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2c603",
   "metadata": {},
   "source": [
    "#### Sample Growing Data\n",
    "\n",
    "Observe the effect of growing the sample size on the training and validation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [100, 500, 1000, 5000]\n",
    "\n",
    "# K range list\n",
    "K_list = range(1,21)\n",
    "\n",
    "for s in sizes:\n",
    "    # select s random samples from train dataset\n",
    "    x_subset, y_subset = x[inds[:s]], y[inds[:s]]\n",
    "    \n",
    "    # apply cross validation to get validation and train accuracy matrices \n",
    "    err_val_matrix, err_train_matrix = my_validation.knn_cross_validation(x_subset, y_subset, K_list, L, my_validation.error_rate)\n",
    "    \n",
    "    err_val_means = np.mean(err_val_matrix, axis=1)\n",
    "    \n",
    "    plt.title('Error Rate of KNN for Varying K Values with {size} Samples'.format(size = s))\n",
    "    plt.plot(K_list, np.mean(err_train_matrix, axis=1),  label='train')\n",
    "    plt.errorbar(K_list, err_val_means, np.std(err_val_matrix, axis=1), label='validation')\n",
    "    plt.legend()\n",
    "    plt.xlabel('K (number of neighbours)')\n",
    "    plt.ylabel('error rate')\n",
    "    plt.ylim(0,0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0566c43",
   "metadata": {},
   "source": [
    "#### Use Best Parameter on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train)\n",
    "tr_time = time.time() - start\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "pred_time = time.time() - tr_time\n",
    "\n",
    "err_rate = my_validation.error_rate(y_test, y_pred)\n",
    "\n",
    "print(\"Error Rate on Test Set: {err_rate}\".format(err_rate=err_rate))\n",
    "print(\"Training time: {tr_time}\".format(tr_time=tr_time))\n",
    "print(\"Prediction time: {pred_time}\".format(pred_time=pred_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff69ada",
   "metadata": {},
   "source": [
    "### 2. DECISION-TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e1341",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eda608",
   "metadata": {},
   "source": [
    "#### Sample-Growing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8fc10e",
   "metadata": {},
   "source": [
    "#### Use Best Parameter Combination on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eae5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
